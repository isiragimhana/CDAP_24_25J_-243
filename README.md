#CDAP_24_25J_-243

 
SMART NAVIGATION AND INFORMATION COMPANION MOBILE APP FOR ZOO EXPLORERS 


RESEARCH PROBLEM

"How can a mobile application effectively provide  contextual information to enhance the visitor experience in a zoo, while accommodating diverse user needs and promoting wildlife education and conservation awareness?"




OBJECTIVES
"To provide an engaging, educational, and seamless experience for visitors while promoting awareness of wildlife conservation and ensuring efficient navigation of the zoo."

Sub objective 1
Scan animals and identify there details.

Sub objective 2
Using visual navigation system & sign identifier for visitors

Sub objective 3
Live Zoo Cam Adventures.

Sub objective 4
Virtul chat bot


OVERALL PROJECT OBJECTIVES

![Image p (Whiteboard)](https://github.com/user-attachments/assets/0f1d188e-4d0f-4c61-a061-437286e0df91)


Technologies and Algorithms
![Image p (Whiteboard) (2)](https://github.com/user-attachments/assets/bc344ce4-23e5-461c-8917-7a07f11ba448)



Scan animals and identify there details.
Bandara D.M.H.G.I.G
IT21239670

RESEARCH 
QUESTIONS

What image processing techniques are most effective for accurate  identification of animal breeds ?​

How can advanced machine learning and deep learning models be utilized for animal details identification, and what performance metrics are best suited to evaluate their accuracy ?

solution

To accurately identify animal breeds, use deep learning-based models such as Convolutional Neural Networks (CNNs) like ResNet, DenseNet, or EfficientNet. These models can automatically extract and classify features from animal images. Preprocess data through normalization, augmentation, and contrast enhancement techniques to improve model performance. Use semantic segmentation methods, like Mask R-CNN, to isolate animals from backgrounds for focused feature extraction.

For implementing machine learning and deep learning techniques to identify animal details, employ transfer learning with pre-trained models. Fine-tune these models on your dataset for higher accuracy. Integrate attention mechanisms or ensemble methods to enhance feature extraction and decision-making. Evaluate model performance using metrics such as accuracy, precision, recall, F1 score, and IoU for segmentation tasks. Optimize inference time and model size for real-time applications.


Architecture Diagram

![Image p (Whiteboard) (1)](https://github.com/user-attachments/assets/2f2297d8-2a3b-41d2-8e37-fbe96a660434)



Using visual navigation system & sign identifier  for visitors.
K.A.E Nuwanga 
IT21339738


RESEARCH 
QUESTIONS

What image processing techniques are most effective for accurate  identification of signs & bords in zoo ?​


How can a mobile application effectively provide real-time navigation  to enhance the visitor experience in a zoo


 solution

To accurately identify signs and boards in a zoo, use Optical Character Recognition (OCR) combined with deep learning models like YOLO, Faster R-CNN, or SSD for object detection. Preprocess images with contrast enhancement, noise reduction, and edge detection to improve readability and accuracy. Apply segmentation techniques to isolate text or symbols from the background for precise identification.

For real-time navigation in a zoo through a mobile application, integrate GPS with Indoor Positioning Systems (IPS) using technologies like Bluetooth beacons, Wi-Fi triangulation, or QR codes. Implement augmented reality (AR) overlays for direction guidance and point-of-interest identification. Use user-friendly interfaces with real-time updates, route optimization, and multilingual support to enhance the visitor experience.



Virtual chatbot for
zoo visitors

Weihena K.M
IT21168604


RESEARCH 
QUESTIONS

How does the integration of a virtual chat bot within a zoo's mobile app impact visitorengagement, satisfaction, and learning by providing real-time information, personalized navigation, and interactive educational features.

what are the key factors that contribute to its effectiveness in enhancing the overall zoo experience?


solution


The integration of a virtual chatbot within a zoo's mobile app enhances visitor engagement, satisfaction, and learning by providing instant access to real-time information, personalized navigation assistance, and interactive educational features. The chatbot leverages natural language processing (NLP) to answer queries, recommend routes, and share animal facts or conservation messages tailored to user preferences.

Key factors contributing to its effectiveness include seamless integration with the app’s interface, multilingual support, responsiveness, and accurate content delivery. Incorporating voice-based interactions, gamified educational experiences, and user feedback mechanisms further improves usability and engagement. Reliable performance, intuitive design, and regular updates are essential for enhancing the overall zoo experience.


Architecture Diagram


![Image p (Whiteboard) (3)](https://github.com/user-attachments/assets/cf8c132a-0609-402e-987d-f4ba4d02860d)


Smart Navigation and Information Companion for Zoo Explorers 

Venujan Yogathas 
IT21189012


RESEARCH QUESTIONS

How can high-definition live camera feeds be optimized for low-latency streaming in a zoo environment?

What user interface design principles are most effective for live feed interaction in mobile applications?

How can object detection works for animal detection?


solution


High-definition live camera feeds can be optimized for low-latency streaming in a zoo environment by using adaptive bitrate streaming (ABR), efficient video codecs like H.265/HEVC, and WebRTC protocols. Implement edge computing for local processing and leverage Content Delivery Networks (CDNs) for faster data distribution. Ensure stable network infrastructure with high-speed connectivity and bandwidth prioritization.

Effective user interface design principles for live feed interaction in mobile applications include intuitive navigation, responsive controls, and clutter-free layouts. Incorporate features like pinch-to-zoom, real-time annotations, and multi-feed switching for enhanced usability. Ensure accessibility with clear icons, high-contrast visuals, and minimal latency.

Object detection for animal detection works by training machine learning models, such as YOLO or Faster R-CNN, on labeled datasets of animal images. These models use convolutional neural networks (CNNs) to detect and classify animals in real-time by analyzing patterns, shapes, and textures in the input video or image streams.



Architecture Diagram

![Image p (Whiteboard) (4)](https://github.com/user-attachments/assets/ab756eb5-c18f-463e-bba0-0c01ff8c77a4)










